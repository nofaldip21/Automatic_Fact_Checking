{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Lwoht4VHSn-h"
   },
   "source": [
    "Training The Bert Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 26219,
     "status": "ok",
     "timestamp": 1684137468798,
     "user": {
      "displayName": "nofaldi putranto",
      "userId": "12902764637369842132"
     },
     "user_tz": -600
    },
    "id": "s7pVrHyHSukn",
    "outputId": "42a04e18-e527-4b7d-8ebf-af39866c8ea0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
      "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (2.0.0+cu118)\n",
      "Requirement already satisfied: torchvision in /usr/local/lib/python3.10/dist-packages (0.15.1+cu118)\n",
      "Collecting transformers\n",
      "  Downloading transformers-4.29.1-py3-none-any.whl (7.1 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.1/7.1 MB\u001b[0m \u001b[31m32.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch) (3.12.0)\n",
      "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch) (4.5.0)\n",
      "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch) (1.11.1)\n",
      "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch) (3.1)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.2)\n",
      "Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.10/dist-packages (from torch) (2.0.0)\n",
      "Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch) (3.25.2)\n",
      "Requirement already satisfied: lit in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch) (16.0.3)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torchvision) (1.22.4)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from torchvision) (2.27.1)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.10/dist-packages (from torchvision) (8.4.0)\n",
      "Collecting huggingface-hub<1.0,>=0.14.1 (from transformers)\n",
      "  Downloading huggingface_hub-0.14.1-py3-none-any.whl (224 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m224.5/224.5 kB\u001b[0m \u001b[31m18.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (23.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2022.10.31)\n",
      "Collecting tokenizers!=0.11.3,<0.14,>=0.11.1 (from transformers)\n",
      "  Downloading tokenizers-0.13.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.8 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.8/7.8 MB\u001b[0m \u001b[31m85.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.65.0)\n",
      "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.14.1->transformers) (2023.4.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch) (2.1.2)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision) (1.26.15)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision) (2022.12.7)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision) (2.0.12)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision) (3.4)\n",
      "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch) (1.3.0)\n",
      "Installing collected packages: tokenizers, huggingface-hub, transformers\n",
      "Successfully installed huggingface-hub-0.14.1 tokenizers-0.13.3 transformers-4.29.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
      "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
      "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
      "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
      "[nltk_data] Downloading package wordnet to /root/nltk_data...\n"
     ]
    }
   ],
   "source": [
    "!pip install torch torchvision transformers\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "import string\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import json\n",
    "import math\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import time\n",
    "from transformers import BertModel\n",
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "from transformers import BertTokenizer\n",
    "import pandas as pd\n",
    "from nltk.stem import PorterStemmer, WordNetLemmatizer\n",
    "\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')\n",
    "nltk.download('wordnet')\n",
    "\n",
    "#list all stopword and punctuation\n",
    "stopWords = set(list(stopwords.words('english')) + list(string.punctuation))\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "# function to lemmatize word\n",
    "def processLemma(text) :\n",
    "    wordLemma = lemmatizer.lemmatize(text, 'v')\n",
    "    if wordLemma == text:\n",
    "        wordLemma = lemmatizer.lemmatize(text, 'n')\n",
    "    return wordLemma  \n",
    "\n",
    "# funstion to pre processing text\n",
    "def textPreprocess(text):\n",
    "    wordTokenize = word_tokenize(text)\n",
    "    wordTokenize = [word.lower() for word in wordTokenize if (word.lower() not in stopWords) & (word.lower().isalpha())]\n",
    "    lemmatizedTokens = [processLemma(word) for word in wordTokenize if len(processLemma(word)) > 1 ]\n",
    "    return \" \".join(lemmatizedTokens)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 37342,
     "status": "ok",
     "timestamp": 1684137510327,
     "user": {
      "displayName": "nofaldi putranto",
      "userId": "12902764637369842132"
     },
     "user_tz": -600
    },
    "id": "nmrbzLKRTbwc",
    "outputId": "699c0100-0c64-4efb-adeb-4bbd11f1cebb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mounted at /content/drive\n"
     ]
    }
   ],
   "source": [
    "# load section\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n",
    "# please change the folder path depend on your path location\n",
    "folderPath = '/content/drive/MyDrive/Colab Notebooks/Assignment 3 NLP/project-data/Submission Folder/'\n",
    "with open(folderPath + \"/Folder dataset/train-claims.json\", 'r') as f:\n",
    "    trainData = json.load(f)\n",
    "with open(folderPath  + '/TF-IDF embedding and vectorize/vectorize_tfIdf_without_new.pkl', 'rb') as handle:\n",
    "    vectorizer = pickle.load(handle)\n",
    "with open(folderPath + '/TF-IDF embedding and vectorize/evidence_list.pkl', 'rb') as handle:\n",
    "  evidenceList = pickle.load(handle)\n",
    "with open(folderPath + '/TF-IDF embedding and vectorize/embedding_tfidf_without_new.pkl', 'rb') as handle:\n",
    "    tfIdfMatrix = pickle.load(handle)\n",
    "with open(folderPath  + '/Folder dataset/evidence.json','r') as f :\n",
    "    dictEvidence = json.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0XGQDiQnZu0D"
   },
   "source": [
    "Generate Class Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "executionInfo": {
     "elapsed": 437,
     "status": "ok",
     "timestamp": 1684137515222,
     "user": {
      "displayName": "nofaldi putranto",
      "userId": "12902764637369842132"
     },
     "user_tz": -600
    },
    "id": "kqUH1NWCZfTb"
   },
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset\n",
    "\n",
    "class TrainedDataset(Dataset):\n",
    "\n",
    "    def __init__(self, filename,maxlen):\n",
    "\n",
    "        self.tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "\n",
    "        self.maxlen = maxlen  \n",
    "        self.df = pd.read_csv(filename,sep=\"\\t\")\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "\n",
    "        #Selecting the sentence and label at the specified index in the data frame\n",
    "        target_sentence = textPreprocess(self.df.loc[index, 'target_sentence'])\n",
    "        evidence_sentence = textPreprocess(self.df.loc[index, 'evidence_sentence'])\n",
    "        label = self.df.loc[index, 'label']\n",
    "\n",
    "        #Preprocessing the text to be suitable for BERT\n",
    "        halfLen = math.ceil(self.maxlen/2) - 1\n",
    "        tokens_target = self.tokenizer.tokenize(target_sentence) #Tokenize the sentence\n",
    "        seg_ids_target = [0 for _ in range(len(tokens_target))]\n",
    "        tokens_evidence = self.tokenizer.tokenize(evidence_sentence)\n",
    "        seg_ids_evidence = [1 for _ in range(len(tokens_evidence))] \n",
    "        tokens = ['[CLS]'] + tokens_target[:halfLen] + ['[SEP]'] + tokens_evidence[:halfLen] + ['[SEP]']#Insering the CLS and SEP token in the beginning and end of the sentence\n",
    "        seg_ids = [0] + seg_ids_target[:halfLen] + [0] + seg_ids_evidence[:halfLen] + [1]\n",
    "        if len(tokens) < self.maxlen:\n",
    "            seg_ids = seg_ids + [1 for _ in range(self.maxlen - len(tokens))]\n",
    "            tokens = tokens + ['[PAD]' for _ in range(self.maxlen - len(tokens))] #Padding sentences\n",
    "        else:\n",
    "            tokens = tokens[:self.maxlen-1] + ['[SEP]'] #Prunning the list to be of specified max length\n",
    "            seg_ids = seg_ids[:self.maxlen]\n",
    "\n",
    "        tokens_ids = self.tokenizer.convert_tokens_to_ids(tokens) #Obtaining the indices of the tokens in the BERT Vocabulary\n",
    "        tokens_ids_tensor = torch.tensor(tokens_ids) #Converting the list to a pytorch tensor\n",
    "        seg_ids_tensor = torch.tensor(seg_ids)\n",
    "\n",
    "        #Obtaining the attention mask i.e a tensor containing 1s for no padded tokens and 0s for padded ones\n",
    "        attn_mask = (tokens_ids_tensor != 0).long()\n",
    "\n",
    "        return tokens_ids_tensor, attn_mask,seg_ids_tensor, label"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "t8x2fK1PZ8zt"
   },
   "source": [
    "Generate Sentiment Classification Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "executionInfo": {
     "elapsed": 3,
     "status": "ok",
     "timestamp": 1684137520141,
     "user": {
      "displayName": "nofaldi putranto",
      "userId": "12902764637369842132"
     },
     "user_tz": -600
    },
    "id": "Moaa7YpUZ3nw"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from transformers import BertModel\n",
    "\n",
    "class SentimentClassifier(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super(SentimentClassifier, self).__init__()\n",
    "        #Instantiating BERT model object \n",
    "        self.bert_layer = BertModel.from_pretrained('bert-base-uncased')\n",
    "        \n",
    "        #Classification layer\n",
    "        #input dimension is 768 because [CLS] embedding has a dimension of 768\n",
    "        #output dimension is 1 because we're working with a binary classification problem\n",
    "        self.cls_layer = nn.Linear(768, 1)\n",
    "\n",
    "    def forward(self, seq, attn_masks,seg_ids):\n",
    "        '''\n",
    "        Inputs:\n",
    "            -seq : Tensor of shape [B, T] containing token ids of sequences\n",
    "            -attn_masks : Tensor of shape [B, T] containing attention masks to be used to avoid contibution of PAD tokens\n",
    "        '''\n",
    "\n",
    "        #Feeding the input to BERT model to obtain contextualized representations\n",
    "        outputs = self.bert_layer(seq, attention_mask = attn_masks,token_type_ids = seg_ids, return_dict=True)\n",
    "        cont_reps = outputs.last_hidden_state\n",
    "\n",
    "        #Obtaining the representation of [CLS] head (the first token)\n",
    "        cls_rep = cont_reps[:, 0]\n",
    "\n",
    "        #Feeding cls_rep to the classifier layer\n",
    "        logits = self.cls_layer(cls_rep)\n",
    "\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 153,
     "referenced_widgets": [
      "229ff163771f4e0ebae17fd873fd6f14",
      "63c7c808bdcb414abcbfb96dbb034a5d",
      "c3ceae20cfd94d05a66675bbb67fb125",
      "4e0afc05f436440cb2799f55fbdb6966",
      "f0add8a71f70428f97becbc5facf1452",
      "1bbe4b55d91a4fc5a292549c4e8e5942",
      "3651d64a5cdb4c1c91aaa72e43f68f0d",
      "6a1766f27bae4c8f9e129f1c46eed6e1",
      "66c10ae1b20f4c0888316f711b921c75",
      "970d1fadd6404fdd9713595f22dea193",
      "f351ff86a04740b3b780d959c04f355a",
      "dcee73d656ca45e9996c961f8e382f3f",
      "61dff2fe76a247218a368049e0acfea8",
      "3ec7d008b6754fba9b8aef49d2174880",
      "387b4b2160dd4e448d23d3c1e00dbe65",
      "ede37a7df0cd4cf880ace7fda459ca58",
      "74947a07d96c472294cf1a26aaefb4f7",
      "72c8c283ce354c12a70021c370199dc8",
      "0ea16591de0f4782901319623ed3634a",
      "436d134b132a4774bc337c1ffd35d017",
      "77e4e79ea2c542f99f134fb235e4837d",
      "f350faecd35545108c5f40942c169253"
     ]
    },
    "executionInfo": {
     "elapsed": 14741,
     "status": "ok",
     "timestamp": 1684137541501,
     "user": {
      "displayName": "nofaldi putranto",
      "userId": "12902764637369842132"
     },
     "user_tz": -600
    },
    "id": "yhK7xexbaEi1",
    "outputId": "e41e7cb6-ee12-4bf2-9339-7ff04de5b89d"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "229ff163771f4e0ebae17fd873fd6f14",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)lve/main/config.json:   0%|          | 0.00/570 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dcee73d656ca45e9996c961f8e382f3f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading pytorch_model.bin:   0%|          | 0.00/440M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.decoder.weight', 'cls.seq_relationship.bias', 'cls.predictions.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "net = SentimentClassifier()\n",
    "# saved_model = torch.load(folderPath + 'Saved Model/sstcls_1_512_balance_modif.dat')\n",
    "# net.load_state_dict(saved_model)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "net.to(device)\n",
    "\n",
    "if torch.cuda.device_count() > 1:\n",
    "    print(\"Using\", torch.cuda.device_count(), \"GPUs\")\n",
    "    net = nn.DataParallel(net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "executionInfo": {
     "elapsed": 2,
     "status": "ok",
     "timestamp": 1684137650264,
     "user": {
      "displayName": "nofaldi putranto",
      "userId": "12902764637369842132"
     },
     "user_tz": -600
    },
    "id": "jriisqYEa5Uf"
   },
   "outputs": [],
   "source": [
    "def get_accuracy_from_logits(logits, labels):\n",
    "    probs = torch.sigmoid(logits.unsqueeze(-1))\n",
    "    soft_probs = (probs > 0.2).long()\n",
    "    acc = (soft_probs.squeeze() == labels).float().mean()\n",
    "    return acc\n",
    "\n",
    "# Calculate real F1 not the mean\n",
    "def get_accuracy_F1_element(logits, labels) :\n",
    "    probs = torch.sigmoid(logits.unsqueeze(-1))\n",
    "    soft_probs = (probs > 0.2).long()\n",
    "    TP = torch.sum((soft_probs.squeeze() == 1) & (labels == 1))\n",
    "    FP = torch.sum((soft_probs.squeeze() == 1) & (labels == 0))\n",
    "    FN = torch.sum((soft_probs.squeeze() == 0) & (labels == 1))\n",
    "    return TP,FP,FN\n",
    "\n",
    "# Mean of F1\n",
    "def calculateTheF1(logits, labels):\n",
    "    probs = torch.sigmoid(logits.unsqueeze(-1))\n",
    "    soft_probs = (probs > 0.2).long()\n",
    "    TP = torch.sum((soft_probs.squeeze() == 1) & (labels == 1))\n",
    "    FP = torch.sum((soft_probs.squeeze() == 1) & (labels == 0))\n",
    "    FN = torch.sum((soft_probs.squeeze() == 0) & (labels == 1))\n",
    "    if (TP + FN) == 0 :\n",
    "      recall = 0\n",
    "    else :\n",
    "      recall = TP / (TP + FN)\n",
    "    if (TP + FP) == 0 :\n",
    "      precision = 0\n",
    "    else :\n",
    "      precision = TP / (TP + FP)\n",
    "    if (precision + recall) == 0 :\n",
    "      F1 = 0\n",
    "    else :\n",
    "      F1 = 2 * precision * recall / (precision + recall)\n",
    "    return F1\n",
    "\n",
    "def evaluate(net, criterion, dataloader,device):\n",
    "    net.eval()\n",
    "\n",
    "    mean_acc, mean_loss = 0, 0\n",
    "    TP,FP,FN = 0,0,0\n",
    "    F1 = 0\n",
    "    count = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for seq, attn_masks,seg_ids, labels in dataloader:\n",
    "            seq, attn_masks,seg_ids, labels = seq.to(device), attn_masks.to(device),seg_ids.to(device), labels.to(device)\n",
    "            logits = net(seq, attn_masks,seg_ids)\n",
    "            mean_loss += criterion(logits.squeeze(-1), labels.float()).item()\n",
    "            mean_acc += get_accuracy_from_logits(logits, labels)\n",
    "            F1 += calculateTheF1(logits, labels)\n",
    "            TP_Temp,FN_temp,FP_temp = get_accuracy_F1_element(logits, labels)\n",
    "            TP += TP_Temp\n",
    "            FN += FN_temp\n",
    "            FP += FP_temp\n",
    "            count += 1\n",
    "    F1_result = TP / (TP+0.5*(FP+FN))\n",
    "    #print(count)\n",
    "    return mean_acc / count, mean_loss / count,F1 / count,F1_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "executionInfo": {
     "elapsed": 3,
     "status": "ok",
     "timestamp": 1684137684971,
     "user": {
      "displayName": "nofaldi putranto",
      "userId": "12902764637369842132"
     },
     "user_tz": -600
    },
    "id": "q6j0bekSbS-V"
   },
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "def train(net, criterion, opti, train_loader, dev_loader, max_eps, device):\n",
    "\n",
    "    best_acc = 0\n",
    "    st = time.time()\n",
    "    for ep in range(max_eps):\n",
    "        \n",
    "        net.train()\n",
    "        for it, (seq, attn_masks,seg_ids, labels) in enumerate(train_loader):\n",
    "            #Clear gradients\n",
    "            opti.zero_grad()  \n",
    "            #Converting these to cuda tensors\n",
    "            seq, attn_masks, seg_ids ,labels = seq.to(device), attn_masks.to(device),seg_ids.to(device), labels.to(device)\n",
    "\n",
    "            #Obtaining the logits from the model\n",
    "            logits = net(seq, attn_masks,seg_ids)\n",
    "\n",
    "            #Computing loss\n",
    "            loss = criterion(logits.squeeze(-1), labels.float())\n",
    "\n",
    "\n",
    "            #Backpropagating the gradients\n",
    "            loss.backward()\n",
    "\n",
    "            #Optimization step\n",
    "            opti.step()\n",
    "              \n",
    "            if it % 100 == 0:\n",
    "                \n",
    "                acc = get_accuracy_from_logits(logits, labels)\n",
    "                F1_result = calculateTheF1(logits, labels)\n",
    "                print(\"Iteration {} of epoch {} complete. Loss: {}; Accuracy: {}; F1-result: {}; ;Time taken (s): {}\".format(it, ep, loss.item(), acc,F1_result, (time.time()-st)))\n",
    "                st = time.time()\n",
    "\n",
    "        \n",
    "        dev_acc, dev_loss,F1_result,_ = evaluate(net, criterion, dev_loader, device)\n",
    "        print(\"Epoch {} complete! Development Accuracy: {}; Development Loss: {}; Development F1: {}\".format(ep, dev_acc, dev_loss,F1_result))\n",
    "        if F1_result > best_acc:\n",
    "            print(\"Best development accuracy improved from {} to {}, saving model...\".format(best_acc, F1_result))\n",
    "            best_acc = F1_result\n",
    "            torch.save(net.state_dict(), folderPath + 'sstcls_{}_512_for_100_wiki_model.dat'.format(ep))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1694,
     "status": "ok",
     "timestamp": 1684138046550,
     "user": {
      "displayName": "nofaldi putranto",
      "userId": "12902764637369842132"
     },
     "user_tz": -600
    },
    "id": "biSse7WhbcRj",
    "outputId": "ff87232e-e1c6-4b63-ed51-bf6c05c05bec"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done preprocessing training and development data.\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "import numpy as np\n",
    "\n",
    "#Creating instances of training and development set\n",
    "#maxlen sets the maximum length a sentence can have\n",
    "#any sentence longer than this length is truncated to the maxlen size\n",
    "train_set = TrainedDataset(filename = folderPath + 'saved dataset/train-claims-dataset-cosine-100.csv', maxlen = 60)\n",
    "dev_set = TrainedDataset(filename = folderPath + 'saved dataset/dev-dataset-cosine-100.csv', maxlen = 60)\n",
    "\n",
    "\n",
    "#Creating intsances of training and development dataloaders\n",
    "train_loader = DataLoader(train_set, batch_size = 100, num_workers = 2)\n",
    "dev_loader = DataLoader(dev_set, batch_size = 100, num_workers = 2)\n",
    "\n",
    "print(\"Done preprocessing training and development data.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "executionInfo": {
     "elapsed": 2,
     "status": "ok",
     "timestamp": 1684138076628,
     "user": {
      "displayName": "nofaldi putranto",
      "userId": "12902764637369842132"
     },
     "user_tz": -600
    },
    "id": "p4aIsw--c2Hw"
   },
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "\n",
    "criterion = nn.BCEWithLogitsLoss()\n",
    "opti = optim.Adam(net.parameters(), lr = 2e-5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qnP0BngSdYlK"
   },
   "source": [
    "If train data is needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8HG9g3MRc7U0"
   },
   "outputs": [],
   "source": [
    "num_epoch = 2\n",
    "\n",
    "#fine-tune the model\n",
    "train(net, criterion, opti, train_loader, dev_loader, num_epoch,device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FRyjntOgdAwK"
   },
   "source": [
    "Generate Test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "executionInfo": {
     "elapsed": 1,
     "status": "ok",
     "timestamp": 1684138243032,
     "user": {
      "displayName": "nofaldi putranto",
      "userId": "12902764637369842132"
     },
     "user_tz": -600
    },
    "id": "tcqBBHRxddQ5"
   },
   "outputs": [],
   "source": [
    "def predict(net,dataloader,top10Value,device):\n",
    "    net.eval()\n",
    "    logitsList = []\n",
    "    with torch.no_grad():\n",
    "        for seq, attn_masks,seg_ids in tested_loader:\n",
    "            seq, attn_masks,seg_ids = seq.to(device), attn_masks.to(device),seg_ids.to(device)\n",
    "            logits = net(seq, attn_masks,seg_ids)\n",
    "            probs = torch.sigmoid(logits.unsqueeze(-1))\n",
    "            logitsList += probs.squeeze().tolist()\n",
    "    combinedList = sorted(zip(logitsList, evidence_test), reverse=True)\n",
    "    top5Elements = [e for s, e in combinedList[:5]]\n",
    "    if len(top5Elements) == 0 :\n",
    "      top5Elements = [e for s, e in combinedList[:5]]\n",
    "    topSentence = [dictEvidence[e] for e in top5Elements]\n",
    "    return top5Elements , topSentence"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "j8c_jfVUdoWg"
   },
   "source": [
    "Build Test Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "executionInfo": {
     "elapsed": 646,
     "status": "ok",
     "timestamp": 1684138294869,
     "user": {
      "displayName": "nofaldi putranto",
      "userId": "12902764637369842132"
     },
     "user_tz": -600
    },
    "id": "ZVwD7X5bdjr0"
   },
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset\n",
    "\n",
    "class TestedDataset(Dataset):\n",
    "\n",
    "    def __init__(self, df, maxlen):\n",
    "\n",
    "        self.tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "\n",
    "        self.maxlen = maxlen  \n",
    "        self.df = df\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "\n",
    "        #Selecting the sentence and label at the specified index in the data frame\n",
    "        target_sentence = self.df.loc[index, 'target_sentence']\n",
    "        evidence_sentence = self.df.loc[index, 'evidence_sentence']\n",
    "\n",
    "        #Preprocessing the text to be suitable for BERT\n",
    "        halfLen = math.ceil(self.maxlen/2) - 1\n",
    "        tokens_target = self.tokenizer.tokenize(target_sentence) #Tokenize the sentence\n",
    "        seg_ids_target = [0 for _ in range(len(tokens_target))]\n",
    "        tokens_evidence = self.tokenizer.tokenize(evidence_sentence)\n",
    "        seg_ids_evidence = [1 for _ in range(len(tokens_evidence))] \n",
    "        tokens = ['[CLS]'] + tokens_target[:halfLen] + ['[SEP]'] + tokens_evidence[:halfLen] + ['[SEP]']#Insering the CLS and SEP token in the beginning and end of the sentence\n",
    "        seg_ids = [0] + seg_ids_target[:halfLen] + [0] + seg_ids_evidence[:halfLen] + [1]\n",
    "        if len(tokens) < self.maxlen:\n",
    "            seg_ids = seg_ids + [1 for _ in range(self.maxlen - len(tokens))]\n",
    "            tokens = tokens + ['[PAD]' for _ in range(self.maxlen - len(tokens))] #Padding sentences\n",
    "        else:\n",
    "            tokens = tokens[:self.maxlen-1] + ['[SEP]'] #Prunning the list to be of specified max length\n",
    "            seg_ids = seg_ids[:self.maxlen]\n",
    "\n",
    "        tokens_ids = self.tokenizer.convert_tokens_to_ids(tokens) #Obtaining the indices of the tokens in the BERT Vocabulary\n",
    "        tokens_ids_tensor = torch.tensor(tokens_ids) #Converting the list to a pytorch tensor\n",
    "        seg_ids_tensor = torch.tensor(seg_ids)\n",
    "\n",
    "        #Obtaining the attention mask i.e a tensor containing 1s for no padded tokens and 0s for padded ones\n",
    "        attn_mask = (tokens_ids_tensor != 0).long()\n",
    "\n",
    "        return tokens_ids_tensor, attn_mask,seg_ids_tensor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RJWskt01dzo4"
   },
   "source": [
    "Generate Top 100 for testing dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "executionInfo": {
     "elapsed": 3,
     "status": "ok",
     "timestamp": 1684138355668,
     "user": {
      "displayName": "nofaldi putranto",
      "userId": "12902764637369842132"
     },
     "user_tz": -600
    },
    "id": "oKLJqFSldxFX"
   },
   "outputs": [],
   "source": [
    "def top100(claim_text,k = 100) :\n",
    "  targetSentencePreprocess = textPreprocess(claim_text)\n",
    "  tfidfMatrixTarget = vectorizer.transform([targetSentencePreprocess])\n",
    "  twoMatrixDot = tfidfMatrixTarget.dot(tfIdfMatrix.T)    \n",
    "  arrayMatrixDot = twoMatrixDot.toarray()\n",
    "  sortedList = np.argsort(arrayMatrixDot).tolist()[0]\n",
    "  top10Value = []\n",
    "  list_df = []\n",
    "  m = 1\n",
    "  while len(top10Value) < k :\n",
    "      evidenceTemp = evidenceList[sortedList[-m]]\n",
    "      top10Value.append(evidenceTemp)\n",
    "      m+=1\n",
    "      temp_dict = {}\n",
    "      temp_dict['target_sentence'] = claim_text\n",
    "      temp_dict['evidence_sentence'] = dictEvidence[evidenceTemp]\n",
    "      list_df.append(temp_dict)\n",
    "  return pd.DataFrame(list_df) , top10Value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "executionInfo": {
     "elapsed": 599,
     "status": "ok",
     "timestamp": 1684138417112,
     "user": {
      "displayName": "nofaldi putranto",
      "userId": "12902764637369842132"
     },
     "user_tz": -600
    },
    "id": "dKAr-x9kd_KK"
   },
   "outputs": [],
   "source": [
    "with open(folderPath + '/Folder dataset/dev-claims.json','r') as f :\n",
    "    devData = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 236560,
     "status": "ok",
     "timestamp": 1684138805460,
     "user": {
      "displayName": "nofaldi putranto",
      "userId": "12902764637369842132"
     },
     "user_tz": -600
    },
    "id": "MBMfEoIDeOS1",
    "outputId": "5c1d26fc-2ebf-4298-e85c-45e94432c708"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
      "Requirement already satisfied: sentence_transformers in /usr/local/lib/python3.10/dist-packages (2.2.2)\n",
      "Requirement already satisfied: transformers<5.0.0,>=4.6.0 in /usr/local/lib/python3.10/dist-packages (from sentence_transformers) (4.29.1)\n",
      "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from sentence_transformers) (4.65.0)\n",
      "Requirement already satisfied: torch>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from sentence_transformers) (2.0.0+cu118)\n",
      "Requirement already satisfied: torchvision in /usr/local/lib/python3.10/dist-packages (from sentence_transformers) (0.15.1+cu118)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from sentence_transformers) (1.22.4)\n",
      "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (from sentence_transformers) (1.2.2)\n",
      "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from sentence_transformers) (1.10.1)\n",
      "Requirement already satisfied: nltk in /usr/local/lib/python3.10/dist-packages (from sentence_transformers) (3.8.1)\n",
      "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.10/dist-packages (from sentence_transformers) (0.1.99)\n",
      "Requirement already satisfied: huggingface-hub>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from sentence_transformers) (0.14.1)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.4.0->sentence_transformers) (3.12.0)\n",
      "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.4.0->sentence_transformers) (2023.4.0)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.4.0->sentence_transformers) (2.27.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.4.0->sentence_transformers) (6.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.4.0->sentence_transformers) (4.5.0)\n",
      "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.4.0->sentence_transformers) (23.1)\n",
      "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->sentence_transformers) (1.11.1)\n",
      "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->sentence_transformers) (3.1)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->sentence_transformers) (3.1.2)\n",
      "Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->sentence_transformers) (2.0.0)\n",
      "Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch>=1.6.0->sentence_transformers) (3.25.2)\n",
      "Requirement already satisfied: lit in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch>=1.6.0->sentence_transformers) (16.0.3)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers<5.0.0,>=4.6.0->sentence_transformers) (2022.10.31)\n",
      "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /usr/local/lib/python3.10/dist-packages (from transformers<5.0.0,>=4.6.0->sentence_transformers) (0.13.3)\n",
      "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk->sentence_transformers) (8.1.3)\n",
      "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk->sentence_transformers) (1.2.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->sentence_transformers) (3.1.0)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.10/dist-packages (from torchvision->sentence_transformers) (8.4.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.6.0->sentence_transformers) (2.1.2)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.4.0->sentence_transformers) (1.26.15)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.4.0->sentence_transformers) (2022.12.7)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.4.0->sentence_transformers) (2.0.12)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.4.0->sentence_transformers) (3.4)\n",
      "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.6.0->sentence_transformers) (1.3.0)\n",
      "50\n",
      "83.03092622756958\n",
      "==================================\n",
      "100\n",
      "145.64600825309753\n",
      "==================================\n",
      "150\n",
      "208.22457480430603\n",
      "==================================\n"
     ]
    }
   ],
   "source": [
    "!pip install sentence_transformers\n",
    "from torch.utils.data import DataLoader\n",
    "from sentence_transformers import SentenceTransformer, CrossEncoder, util\n",
    "from statistics import mode\n",
    "import time\n",
    "import numpy as np\n",
    "# you can use it because you don't have pretrain model\n",
    "cross_encoder_part2 = CrossEncoder('distilroberta-base')\n",
    "\n",
    "def getLabels(top5Sentence,claim_text) :\n",
    "  dictClaim = {1 : 'SUPPORTS', 2 : \"REFUTES\", 3: \"NOT_ENOUGH_INFO\", 0 : \"DISPUTED\"}\n",
    "  listPair = []\n",
    "  for i in top5Sentence :\n",
    "    listPair.append([claim_text,i])\n",
    "  scores = cross_encoder_part2.predict(listPair)\n",
    "  listLabel = []\n",
    "  for i in scores.tolist() :\n",
    "    listLabel.append(i.index(max(i)))\n",
    "  return dictClaim [mode(listLabel)]\n",
    "\n",
    "with open(folderPath +'/TF-IDF embedding and vectorize/evidence_list.pkl', 'rb') as handle:\n",
    "    evidenceList = pickle.load(handle)\n",
    "devClaimTest = {}\n",
    "h = 1\n",
    "start_time = time.time()\n",
    "for item,val in devData.items() :\n",
    "  devClaimTest[item] = {}\n",
    "  devClaimTest[item]['claim_text'] = val['claim_text']\n",
    "  data_test , evidence_test = top100(val['claim_text'],k=100)\n",
    "  tested_data = TestedDataset(data_test,maxlen = 60)\n",
    "  tested_loader = DataLoader(tested_data, batch_size = 100, num_workers = 2)\n",
    "  evidenceFinal,top5Sentence = predict(net,tested_loader,evidence_test,device)\n",
    "  devClaimTest[item]['claim_label'] = getLabels(top5Sentence,val['claim_text'])\n",
    "  devClaimTest[item]['evidences'] = evidenceFinal\n",
    "  if h % 50 == 0 :\n",
    "    print(h)\n",
    "    print(time.time() - start_time)\n",
    "    print(\"==================================\")\n",
    "  h += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "executionInfo": {
     "elapsed": 3,
     "status": "ok",
     "timestamp": 1684138813454,
     "user": {
      "displayName": "nofaldi putranto",
      "userId": "12902764637369842132"
     },
     "user_tz": -600
    },
    "id": "RZNd15pVe1Q0"
   },
   "outputs": [],
   "source": [
    "# this file is used for predicting dev-dataset\n",
    "with open(folderPath +\"devTesting.json\", \"w\") as file:\n",
    "    json.dump(devClaimTest, file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MgMyC7BhgHi-"
   },
   "source": [
    "Train The dev dataset to model for testing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "executionInfo": {
     "elapsed": 3,
     "status": "ok",
     "timestamp": 1684139042901,
     "user": {
      "displayName": "nofaldi putranto",
      "userId": "12902764637369842132"
     },
     "user_tz": -600
    },
    "id": "DgiClLYAgPME"
   },
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "def train(net, criterion, opti, train_loader, dev_loader, max_eps, device):\n",
    "\n",
    "    best_acc = 0\n",
    "    st = time.time()\n",
    "    for ep in range(max_eps):\n",
    "        \n",
    "        net.train()\n",
    "        for it, (seq, attn_masks,seg_ids, labels) in enumerate(train_loader):\n",
    "            #Clear gradients\n",
    "            opti.zero_grad()  \n",
    "            #Converting these to cuda tensors\n",
    "            seq, attn_masks, seg_ids ,labels = seq.to(device), attn_masks.to(device),seg_ids.to(device), labels.to(device)\n",
    "\n",
    "            #Obtaining the logits from the model\n",
    "            logits = net(seq, attn_masks,seg_ids)\n",
    "\n",
    "            #Computing loss\n",
    "            loss = criterion(logits.squeeze(-1), labels.float())\n",
    "\n",
    "            #Backpropagating the gradients\n",
    "            loss.backward()\n",
    "\n",
    "            #Optimization step\n",
    "            opti.step()\n",
    "              \n",
    "            if it % 100 == 0:\n",
    "                \n",
    "                acc = get_accuracy_from_logits(logits, labels)\n",
    "                # TP,FN,FP = get_accuracy_F1_element(logits, labels)\n",
    "                # F1_result = TP / (TP+0.5*(FP+FN))\n",
    "                F1_result = calculateTheF1(logits, labels)\n",
    "                print(\"Iteration {} of epoch {} complete. Loss: {}; Accuracy: {}; F1-result: {}; ;Time taken (s): {}\".format(it, ep, loss.item(), acc,F1_result, (time.time()-st)))\n",
    "                st = time.time()\n",
    "\n",
    "        \n",
    "        dev_acc, dev_loss,F1_result,_ = evaluate(net, criterion, dev_loader, device)\n",
    "        print(\"Epoch {} complete! Development Accuracy: {}; Development Loss: {}; Development F1: {}\".format(ep, dev_acc, dev_loss,F1_result))\n",
    "        if F1_result > best_acc:\n",
    "            print(\"Best development accuracy improved from {} to {}, saving model...\".format(best_acc, F1_result))\n",
    "            best_acc = F1_result\n",
    "            torch.save(net.state_dict(), folderPath + 'sstcls_{}_512_for_predicting.dat'.format(ep))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wmChR65ggcQh"
   },
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "#Creating intsances of training and development dataloaders\n",
    "train_set = TrainedDataset(filename = folderPath + 'saved dataset/train-claims-dataset-cosine-100.csv', maxlen = 60)\n",
    "dev_set = TrainedDataset(filename = folderPath + 'saved dataset/dev-dataset-cosine-100.csv', maxlen = 60)\n",
    "\n",
    "train_loader = DataLoader(train_set, batch_size = 100, num_workers = 2)\n",
    "dev_loader = DataLoader(dev_set, batch_size = 100, num_workers = 2)\n",
    "\n",
    "num_epoch = 2\n",
    "\n",
    "#fine-tune the model\n",
    "train(net, criterion, opti, dev_loader,train_loader, num_epoch,device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JPDWtVtzg2cS"
   },
   "source": [
    "We can also load trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "executionInfo": {
     "elapsed": 196992,
     "status": "ok",
     "timestamp": 1684139740688,
     "user": {
      "displayName": "nofaldi putranto",
      "userId": "12902764637369842132"
     },
     "user_tz": -600
    },
    "id": "_D98sFa7hOz4"
   },
   "outputs": [],
   "source": [
    "with open(folderPath + '/Folder dataset/test-claims-unlabelled.json', 'rb') as handle:\n",
    "    dataTest = json.load(handle)\n",
    "\n",
    "ClaimTest = {}\n",
    "for item,val in dataTest.items() :\n",
    "  ClaimTest[item] = {}\n",
    "  ClaimTest[item]['claim_text'] = val['claim_text']\n",
    "  data_test , evidence_test = top100(val['claim_text'])\n",
    "  tested_data = TestedDataset(data_test,maxlen = 60)\n",
    "  tested_loader = DataLoader(tested_data, batch_size = 100, num_workers = 2)\n",
    "  evidenceFinal,top5Sentence = predict(net,tested_loader,evidence_test,device)\n",
    "  ClaimTest[item]['claim_label'] = getLabels(top5Sentence,val['claim_text'])\n",
    "  ClaimTest[item]['evidences'] = evidenceFinal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "executionInfo": {
     "elapsed": 623,
     "status": "ok",
     "timestamp": 1684139797932,
     "user": {
      "displayName": "nofaldi putranto",
      "userId": "12902764637369842132"
     },
     "user_tz": -600
    },
    "id": "6310GhaKhQwW"
   },
   "outputs": [],
   "source": [
    "with open(folderPath + \"TestingSubmit.json\", \"w\") as file:\n",
    "    json.dump(ClaimTest, file)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "authorship_tag": "ABX9TyNRHUZs7/fndvlR68+q+b19",
   "gpuType": "T4",
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "0ea16591de0f4782901319623ed3634a": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "1bbe4b55d91a4fc5a292549c4e8e5942": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "229ff163771f4e0ebae17fd873fd6f14": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_63c7c808bdcb414abcbfb96dbb034a5d",
       "IPY_MODEL_c3ceae20cfd94d05a66675bbb67fb125",
       "IPY_MODEL_4e0afc05f436440cb2799f55fbdb6966"
      ],
      "layout": "IPY_MODEL_f0add8a71f70428f97becbc5facf1452"
     }
    },
    "3651d64a5cdb4c1c91aaa72e43f68f0d": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "387b4b2160dd4e448d23d3c1e00dbe65": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_77e4e79ea2c542f99f134fb235e4837d",
      "placeholder": "​",
      "style": "IPY_MODEL_f350faecd35545108c5f40942c169253",
      "value": " 440M/440M [00:02&lt;00:00, 240MB/s]"
     }
    },
    "3ec7d008b6754fba9b8aef49d2174880": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_0ea16591de0f4782901319623ed3634a",
      "max": 440473133,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_436d134b132a4774bc337c1ffd35d017",
      "value": 440473133
     }
    },
    "436d134b132a4774bc337c1ffd35d017": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "4e0afc05f436440cb2799f55fbdb6966": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_970d1fadd6404fdd9713595f22dea193",
      "placeholder": "​",
      "style": "IPY_MODEL_f351ff86a04740b3b780d959c04f355a",
      "value": " 570/570 [00:00&lt;00:00, 16.2kB/s]"
     }
    },
    "61dff2fe76a247218a368049e0acfea8": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_74947a07d96c472294cf1a26aaefb4f7",
      "placeholder": "​",
      "style": "IPY_MODEL_72c8c283ce354c12a70021c370199dc8",
      "value": "Downloading pytorch_model.bin: 100%"
     }
    },
    "63c7c808bdcb414abcbfb96dbb034a5d": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_1bbe4b55d91a4fc5a292549c4e8e5942",
      "placeholder": "​",
      "style": "IPY_MODEL_3651d64a5cdb4c1c91aaa72e43f68f0d",
      "value": "Downloading (…)lve/main/config.json: 100%"
     }
    },
    "66c10ae1b20f4c0888316f711b921c75": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "6a1766f27bae4c8f9e129f1c46eed6e1": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "72c8c283ce354c12a70021c370199dc8": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "74947a07d96c472294cf1a26aaefb4f7": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "77e4e79ea2c542f99f134fb235e4837d": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "970d1fadd6404fdd9713595f22dea193": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "c3ceae20cfd94d05a66675bbb67fb125": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_6a1766f27bae4c8f9e129f1c46eed6e1",
      "max": 570,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_66c10ae1b20f4c0888316f711b921c75",
      "value": 570
     }
    },
    "dcee73d656ca45e9996c961f8e382f3f": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_61dff2fe76a247218a368049e0acfea8",
       "IPY_MODEL_3ec7d008b6754fba9b8aef49d2174880",
       "IPY_MODEL_387b4b2160dd4e448d23d3c1e00dbe65"
      ],
      "layout": "IPY_MODEL_ede37a7df0cd4cf880ace7fda459ca58"
     }
    },
    "ede37a7df0cd4cf880ace7fda459ca58": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "f0add8a71f70428f97becbc5facf1452": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "f350faecd35545108c5f40942c169253": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "f351ff86a04740b3b780d959c04f355a": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
